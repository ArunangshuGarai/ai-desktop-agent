// src/services/visionService.js - Simplified version without OpenCV
const fs = require('fs-extra');
const path = require('path');
const { execSync } = require('child_process');
const { createWorker } = require('tesseract.js');
const deepseek = require('../utils/deepseek');

class VisionService {
  constructor() {
    this.screenshotsDir = path.join(process.cwd(), 'screenshots');
    fs.ensureDirSync(this.screenshotsDir);
    this.ocrWorker = null;
  }

  /**
   * Initialize OCR worker for text recognition
   */
  async initOCR() {
    if (!this.ocrWorker) {
      this.ocrWorker = await createWorker('eng');
    }
    return this.ocrWorker;
  }

  /**
   * Take a screenshot of the currently active window
   */
  async captureActiveWindow(targetPath = null) {
    try {
      // Generate a unique filename if not provided
      if (!targetPath) {
        const timestamp = Date.now();
        const filename = `screenshot_${timestamp}.png`;
        targetPath = path.join(this.screenshotsDir, filename);
      }
      
      // Use PowerShell to capture the active window on Windows
      if (process.platform === 'win32') {
        const psCommand = `
          Add-Type -AssemblyName System.Windows.Forms
          Add-Type -AssemblyName System.Drawing
          
          $screen = [System.Windows.Forms.Screen]::PrimaryScreen
          $bitmap = New-Object System.Drawing.Bitmap $screen.Bounds.Width, $screen.Bounds.Height
          $graphics = [System.Drawing.Graphics]::FromImage($bitmap)
          $graphics.CopyFromScreen($screen.Bounds.X, $screen.Bounds.Y, 0, 0, $bitmap.Size)
          $bitmap.Save("${targetPath}")
          $graphics.Dispose()
          $bitmap.Dispose()
        `;
        
        execSync(`powershell -Command "${psCommand}"`);
        
        console.log(`Screenshot saved to: ${targetPath}`);
        return {
          success: true,
          path: targetPath
        };
      } else {
        throw new Error('Platform not supported');
      }
    } catch (error) {
      console.error('Error capturing window:', error);
      return { success: false, error: error.message };
    }
  }

  /**
   * Recognize text in a screenshot using OCR
   */
  async recognizeText(imagePath) {
    await this.initOCR();
    
    try {
      const result = await this.ocrWorker.recognize(imagePath);
      
      return {
        success: true,
        text: result.data.text,
        confidence: result.data.confidence
      };
    } catch (error) {
      console.error('Error recognizing text:', error);
      return { success: false, error: error.message };
    }
  }

  /**
   * Analyze screen content using DeepSeek AI
   */
  async analyzeScreenContent(elementsToLookFor) {
    try {
      // First take a screenshot
      const screenshot = await this.captureActiveWindow();
      
      if (!screenshot.success) {
        throw new Error('Failed to capture screen for analysis');
      }
      
      // Use OCR to get text on screen
      const textResult = await this.recognizeText(screenshot.path);
      
      // Ask DeepSeek to analyze screenshot contents
      const prompt = `
        Analyze this screenshot text and identify UI elements.
        
        Screen text content:
        ${textResult.text}
        
        Look for these elements: ${elementsToLookFor.join(', ')}
        
        Return a JSON object with:
        1. The UI elements detected and their approximate locations
        2. The general state of the application
        3. Recommendations for next actions based on the current state
      `;
      
      const analysisResult = await deepseek.generateJSON(prompt);
      
      return {
        success: true,
        screenshot: screenshot.path,
        screenText: textResult.text,
        analysis: analysisResult
      };
    } catch (error) {
      console.error('Error analyzing screen content:', error);
      return { success: false, error: error.message };
    }
  }

  /**
   * Wait for a visual element to appear on screen
   */
  async waitForVisualElement(visualCues, timeout = 10000) {
    try {
      console.log(`Waiting for visual elements: ${visualCues.join(', ')}`);
      
      const startTime = Date.now();
      let found = false;
      
      while (!found && (Date.now() - startTime) < timeout) {
        // Take a screenshot
        const screenshot = await this.captureActiveWindow();
        
        if (!screenshot.success) {
          console.log('Failed to capture screen, retrying...');
          await this.sleep(500);
          continue;
        }
        
        // Get text from screenshot
        const textResult = await this.recognizeText(screenshot.path);
        
        // Check if any visual cue is present in the recognized text
        found = visualCues.some(cue => 
          textResult.text.toLowerCase().includes(cue.toLowerCase())
        );
        
        if (found) {
          console.log(`Found visual element(s): ${visualCues.join(', ')}`);
          return {
            success: true,
            screenshot: screenshot.path,
            matchedElements: visualCues.filter(cue => 
              textResult.text.toLowerCase().includes(cue.toLowerCase())
            )
          };
        }
        
        // Not found yet, wait and retry
        console.log('Visual elements not found, waiting...');
        await this.sleep(1000);
      }
      
      // Timeout reached
      if (!found) {
        throw new Error(`Timed out waiting for visual elements: ${visualCues.join(', ')}`);
      }
    } catch (error) {
      console.error('Error waiting for visual element:', error);
      return { success: false, error: error.message };
    }
  }

  /**
   * Recognize text in a specific region and verify expected text
   */
  async recognizeTextInRegion(regionName, expectedText) {
    try {
      // Take a screenshot
      const screenshot = await this.captureActiveWindow();
      
      if (!screenshot.success) {
        throw new Error('Failed to capture screen for text recognition');
      }
      
      // Get all text from screenshot
      const textResult = await this.recognizeText(screenshot.path);
      
      if (!textResult.success) {
        throw new Error('Text recognition failed');
      }
      
      // For simplicity, we're checking the entire screen text
      const text = textResult.text.toLowerCase();
      const hasExpectedText = text.includes(expectedText.toLowerCase());
      
      console.log(`Looking for "${expectedText}" in region "${regionName}"`);
      console.log(`Text found: ${hasExpectedText ? 'Yes' : 'No'}`);
      
      return {
        success: hasExpectedText,
        screenshot: screenshot.path,
        regionName,
        expectedText,
        found: hasExpectedText,
        fullText: text
      };
    } catch (error) {
      console.error('Error recognizing text in region:', error);
      return { success: false, error: error.message };
    }
  }

  /**
   * Utility sleep function
   */
  async sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
  
  /**
   * Close OCR worker when done
   */
  async close() {
    if (this.ocrWorker) {
      await this.ocrWorker.terminate();
      this.ocrWorker = null;
    }
  }
}

module.exports = new VisionService();